{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 紀錄一些雜項\n",
    "* [True or False]( http://localhost:8888/notebooks/Documents/GitHub/JupyterNote/Test_note.ipynb#轉型 )\n",
    "* 轉型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## markdown\n",
    "\n",
    "### 連結\n",
    "Markdown支援兩種形式的連結語法：行內和參考兩種形式。\n",
    "不管是哪一種，連結的文字都是用 [方括號] 來標記。  \n",
    "\n",
    "This is [an example](http://example.com/ \"Title\") inline link.  \n",
    "        `This is [an example](http://example.com/ \"Title\") inline link.`\n",
    "\n",
    "[This link](http://example.net/) has no title attribute.  \n",
    "         `[This link](http://example.net/) has no title attribute.`\n",
    "\n",
    "This is [an example] [id] reference-style link.  \n",
    "[id]: http://example.com/  \"Optional Title Here\"  \n",
    "        This is [an example] [id] reference-style link.\n",
    "        [id]: http://example.com/  \"Optional Title Here\"\n",
    "\n",
    "[Google][]  \n",
    "[Google]: http://www.google.com/  \n",
    "        [Google][]\n",
    "        [Google]: http://www.google.com/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True or False\n",
    "奇怪的東西  \n",
    "> 在python True != False   != 1 $\\to$ True != False  and False != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(   True != False   != 1) \n",
    "print( ( True != False ) != 1)\n",
    "print(   True != ( False != 1) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轉型\n",
    "$\\because$ input() $\\rightarrow$ string  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'complex'>\n",
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "#complex number\n",
    "z = 1 + 2j\n",
    "print(type(z))\n",
    "print(abs(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1-1.2246467991473532e-16j)\n",
      "2.718281828459045\n"
     ]
    }
   ],
   "source": [
    "#math \n",
    "import math \n",
    "print((math.e)**((-1j)* math.pi))\n",
    "print(math.exp(1)) #return float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123466\n"
     ]
    }
   ],
   "source": [
    "s = '123456'\n",
    "print(10 + int(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## harkerrank code30 day10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0b110011101110\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "n = 3310#int(input().strip())\n",
    "\n",
    "b = bin(n)\n",
    "print(b)\n",
    "cnt = 1\n",
    "length = 1\n",
    "for i in range(1,len(b)) :\n",
    "    if b[i] is b[i-1] and b[i] == '1':\n",
    "        cnt = cnt + 1\n",
    "        length = max(length, cnt)\n",
    "    else :\n",
    "        cnt = 1\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## harkerrank day11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "arr = []\n",
    "for arr_i in range(6):\n",
    "   arr_t = [int(arr_temp) for arr_temp in input().strip().split(' ')]\n",
    "   arr.append(arr_t)\n",
    "\n",
    "#determine hourglass and make sum\n",
    "hgSum = []\n",
    "l = list(range(3))\n",
    "for i in len(arr):\n",
    "    for j in (arr[i]):\n",
    "        if arr[i][j] != 0 :\n",
    "            tmpls = [arr[]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'c',\n",
       " 'd',\n",
       " 'i',\n",
       " 's']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 原價屋練習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "uRL = 'http://www.coolpc.com.tw/m/m-list.php'\n",
    "#uRL = 'http://www.coolpc.com.tw/evaluate.php' < bs4 lxml會解析錯誤 改成用html5lib\n",
    "\n",
    "res = requests.post(uRL, {'G':7})\n",
    "soup = BeautifulSoup(res.text , 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['金士頓 A400 240G/7mm/讀:500M/寫:450M/TLC顆粒【三年保】, $2600',\n",
       " '金士頓 A400 480G/7mm/讀:500M/寫:450M/TLC顆粒【三年保】, $4588',\n",
       " '金士頓SSDNow UV400 240G雞年限定版(含升級套件組)【三年保】, $2988',\n",
       " '金士頓 UV400 120G/7mm/讀:550M/寫:350M/Marvell/TLC顆粒【三年保】, $1650',\n",
       " '金士頓 UV400 240G/7mm/讀:550M/寫:490M/Marvell/TLC顆粒【三年保】, $2630',\n",
       " '金士頓 UV400 240G/7mm/讀:550M/寫:490M/Marvell/TLC顆粒【三年保】..組裝價, $2580 Hot！',\n",
       " '金士頓 UV400 480G/7mm/讀:550M/寫:500M/Marvell/TLC顆粒【三年保】, $4288',\n",
       " '金士頓 UV400 960G/7mm/讀:550M/寫:500M/Marvell/TLC顆粒【三年保】, $9100',\n",
       " '金士頓 V300 240G/7mm/讀:450M/寫:450M/MLC顆粒【三年保】, $2650',\n",
       " '金士頓 HyperX FURY 120G/7mm/讀:500M/寫:500M/MLC顆粒【三年保】, $1750',\n",
       " 'UMAX S300 240G/7mm讀:540M/寫:490M/SMI/TLC顆粒【三年保】, $2299',\n",
       " 'UMAX S350 256GB /7mm 讀:560MB寫:500MB/3D NAND Flash【三年保】, $2588 Hot！',\n",
       " 'SanDisk X400 128G/7mm讀:540M/寫:340M/Marvell/TLC顆粒/【五年保】, $1770 Hot！',\n",
       " 'SanDisk X400 256G/7mm讀:540M/寫:520M/Marvell/TLC顆粒/【五年保】, $2990↘$2900 Hot！',\n",
       " 'SanDisk X400 512G/7mm讀:540M/寫:520M/Marvell/TLC顆粒/【五年保】, $5199↘$5150',\n",
       " 'SanDisk X400 1TB/7mm讀:540M/寫:520M/Marvell/TLC顆粒/【五年保】, $10150↘$9600',\n",
       " 'Liteon MUIII 240G/7mm讀:555M/寫:470M/TLC顆粒【三年保】, $2250',\n",
       " 'Liteon MUIII Rock 120G/7mm讀:530M/寫:290M/MLC顆粒【三年保】, $1690↘$1588',\n",
       " 'Liteon MUIII Rock 240G/7mm讀:530M/寫:420M/MLC顆粒【三年保】, $2750↘$2488',\n",
       " 'Intel DC S3520系列 150G/讀:450M/寫:380M/MLC顆粒/五年【五年保】伺服器嚴選, $2999 Hot！',\n",
       " 'Intel 540s系列 480G/7mm/讀:560M/寫:480M/TLC顆粒/五年【五年保】, $5500',\n",
       " '威剛 Ultimate SU800 128G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】, $1580',\n",
       " '威剛 Ultimate SU800 256G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】, $2750↘$2680 Hot！',\n",
       " '威剛 Ultimate SU800 512G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】, $4899',\n",
       " '創見 230S系列 128G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】, $1749↘$1650',\n",
       " '創見 230S系列 128G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】..組裝價, $1550',\n",
       " '創見 230S系列 256G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】, $2849↘$2650',\n",
       " '創見 230S系列 256G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】..組裝價, $2688↘$2550',\n",
       " '創見 230S系列 512G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】, $5299↘$4999',\n",
       " '創見 230S系列 512G/7mm/讀:560M/寫:520M/TLC顆粒【三年保】..組裝價, $4888↘$4688',\n",
       " '創見 340K系列 128G/7mm/讀:520M/寫:150M/MLC顆粒【三年保】, $1680',\n",
       " '創見 340K系列 128G/7mm/讀:520M/寫:150M/MLC顆粒【三年保】..組裝價, $1599',\n",
       " '創見 340K系列 256G/7mm/讀:520M/寫:290M/MLC顆粒【三年保】, $2900',\n",
       " '創見 370S系列 128G/7mm/讀:570M/寫:170M/MLC顆粒【三年保】, $1850',\n",
       " '創見 370S系列 256G/7mm/讀:570M/寫:310M/MLC顆粒【三年保】, $3570',\n",
       " '創見 370S系列 512G/7mm/讀:570M/寫:470M/MLC顆粒【加送多功能硬殼旅行收納盒】, $5888 Hot！',\n",
       " '創見 370S系列 1TB/7mm/讀:560M/寫:460M/MLC顆粒【三年保】, $12600↘$11900',\n",
       " 'Toshiba A100 240G/7mm/讀:550M/寫:480M/TLC顆粒【三年保】, $2650',\n",
       " '美光 MX300 275G/7mm/讀:530M/寫:500M/TLC顆粒【三年保】, $2750↘$2730',\n",
       " '美光 MX300 525G/7mm/讀:530M/寫:510M/TLC顆粒【三年保】, $4399↘$4350',\n",
       " '美光 MX300 525G/7mm/讀:530M/寫:510M/TLC顆粒【三年保】..組裝價, $4250',\n",
       " '美光 MX300 1050G/7mm/讀:530M/寫:510M/TLC顆粒【三年保】, $8950↘$8800',\n",
       " '美光 MX300 1050G/7mm/讀:530M/寫:510M/TLC顆粒【三年保】..組裝價, $8500',\n",
       " '美光 MX300 2050G/7mm/讀:530M/寫:510M/TLC顆粒【三年保】, $18400↘$18300',\n",
       " 'WD Green 120G(綠標)/7mm/讀:540M/寫:430M/TLC顆粒【三年保】, $1499',\n",
       " 'WD Blue 250G(藍標)/7mm/讀:540M/寫:500M/TLC顆粒【三年保】, $2499↘$2470',\n",
       " 'WD Blue 500G(藍標)/7mm/讀:545M/寫:525M/TLC顆粒【三年保】, $4650',\n",
       " 'WD Blue 1TB(藍標)/7mm/讀:545M/寫:525M/TLC顆粒【三年保】, $8800↘$8750']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#body > center > span.Q > table:nth-child(1) > tbody \n",
    "#body > center > span.Q > table:nth-child(1) > tbody > tr:nth-child(1) > td\n",
    "stringData = [row.text for row in soup.select('span.Q > table')[0].select('td')]\n",
    "stringData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ptt.cc/bbs/Tech_Job/index1234.html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://www.ptt.cc/bbs/Tech_Job/index{}.html\".format(1234)\n",
    "URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!!!!!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!!!!!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "# training data\n",
    "x_train = [1,2,3,4]\n",
    "y_train = [0,-1,-2,-3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x:x_train, y:y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Java\\AppData\\Local\\Temp\\tmpupl2g310\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000000FAC55F8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Java\\\\AppData\\\\Local\\\\Temp\\\\tmpupl2g310'}\n",
      "WARNING:tensorflow:From C:\\Users\\Java\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Java\\AppData\\Local\\Temp\\tmpupl2g310\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.5, step = 1\n",
      "INFO:tensorflow:global_step/sec: 454.545\n",
      "INFO:tensorflow:loss = 0.0802318, step = 101 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.91\n",
      "INFO:tensorflow:loss = 0.00443985, step = 201 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.161\n",
      "INFO:tensorflow:loss = 0.00154535, step = 301 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.351\n",
      "INFO:tensorflow:loss = 0.000166318, step = 401 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.942\n",
      "INFO:tensorflow:loss = 3.58837e-05, step = 501 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.594\n",
      "INFO:tensorflow:loss = 3.52635e-06, step = 601 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.351\n",
      "INFO:tensorflow:loss = 9.97739e-07, step = 701 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.025\n",
      "INFO:tensorflow:loss = 4.19031e-08, step = 801 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.666\n",
      "INFO:tensorflow:loss = 1.01206e-08, step = 901 (0.150 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Java\\AppData\\Local\\Temp\\tmpupl2g310\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.61826e-09.\n",
      "WARNING:tensorflow:From C:\\Users\\Java\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-05:08:27\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Java\\AppData\\Local\\Temp\\tmpupl2g310\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-05:08:28\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 3.19906e-09\n",
      "WARNING:tensorflow:From C:\\Users\\Java\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-05:08:28\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Java\\AppData\\Local\\Temp\\tmpupl2g310\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-05:08:29\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.00252845\n",
      "train loss: {'loss': 3.199055e-09, 'global_step': 1000}\n",
      "eval loss: {'loss': 0.0025284481, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one real-valued feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# logistic regression, linear classification, logistic classification, and\n",
    "# many neural network classifiers and regressors. The following code\n",
    "# provides an estimator that does linear regression.\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x_train}, y_train,\n",
    "                                              batch_size=4,\n",
    "                                              num_epochs=1000)\n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn(\n",
    "    {\"x\":x_eval}, y_eval, batch_size=4, num_epochs=1000)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train loss: %r\"% train_loss)\n",
    "print(\"eval loss: %r\"% eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "uri = \"mongodb://iiiedu:iiiedu@iiiedubb102-shard-00-00-x7onp.mongodb.net:27017,iiiedubb102-shard-00-01-x7onp.mongodb.net:27017,iiiedubb102-shard-00-02-x7onp.mongodb.net:27017/iiiedubb102?ssl=true&replicaSet=iiiedubb102-shard-0&authSource=admin\"\n",
    "client = pymongo.MongoClient(uri)\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "result = db.restaurants.insert_one(\n",
    "    {\n",
    "        \"address\": {\n",
    "            \"street\": \"2 Avenue\",\n",
    "            \"zipcode\": \"10075\",\n",
    "            \"building\": \"1480\",\n",
    "            \"coord\": [-73.9557413, 40.7720266]\n",
    "        },\n",
    "        \"borough\": \"Manhattan\",\n",
    "        \"cuisine\": \"Italian\",\n",
    "        \"grades\": [\n",
    "            {\n",
    "                \"date\": datetime.strptime(\"2014-10-01\", \"%Y-%m-%d\"),\n",
    "                \"grade\": \"A\",\n",
    "                \"score\": 11\n",
    "            },\n",
    "            {\n",
    "                \"date\": datetime.strptime(\"2014-01-16\", \"%Y-%m-%d\"),\n",
    "                \"grade\": \"B\",\n",
    "                \"score\": 17\n",
    "            }\n",
    "        ],\n",
    "        \"name\": \"Vella\",\n",
    "        \"restaurant_id\": \"41704620\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('5969a971aadaed1d64fa6450')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5969a971aadaed1d64fa6450'),\n",
       " 'address': {'building': '1480',\n",
       "  'coord': [-73.9557413, 40.7720266],\n",
       "  'street': '2 Avenue',\n",
       "  'zipcode': '10075'},\n",
       " 'borough': 'Manhattan',\n",
       " 'cuisine': 'Italian',\n",
       " 'grades': [{'date': datetime.datetime(2014, 10, 1, 0, 0),\n",
       "   'grade': 'A',\n",
       "   'score': 11},\n",
       "  {'date': datetime.datetime(2014, 1, 16, 0, 0), 'grade': 'B', 'score': 17}],\n",
       " 'name': 'Vella',\n",
       " 'restaurant_id': '41704620'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.restaurants.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
